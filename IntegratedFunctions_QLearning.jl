
#=
OVERVIEW:

There will be a Main function that will loop through every week of a season and define the inputs for Q-learning as well as update the Q-table.

    Current Subfunctions that Zahra needs to fill out:
    -PlayerTags - DONE
    -RankingstoPlayers - DONE
    -Rollout - DONE
    -Transition - DONE
    -CalculateReward -DONE
    -QLearning - DONE

    Current Issues that still need to be addressed:
    -How are we accounting for running multiple seasons or multiple initial lineups that all populate the same Q-table?
    -Action exploration strategy 
        -Add checks for which actions are possible: make sure that we check that you don't "switch QB up" if you already have the 1 ranked QB
    -What are we outputting (ideally, a csv file with a bunch of data so we can make plots easily?)
    -Figure out how to handle data for the first iteration (when defining State and Transition State, do we use the week 1 data?)
    -Confirm Reward model (we can always try what I currently have and adjust if the results are dumb)
    -DEBUGGING: issue with rollout function (need to go through and make sure indexing is working as intended) 
        -Need to unify CSV files 
    -DEBUGGING: makeState function giving errors (does it have something to do with indexing?)

    Update 11/26
    -See Issues above
    -There's a bug in the rollout function (has to do with how I'm handling the dataframes) that is messing up the reward function, I'll take a look tomorrow
    -Need to add/format text file output 

    Variables:
        -In dealing with the State we have a few variables:
            -Lineup - dictionary that maps position to player name
            -Rank - dictionary that maps position to ranking of player for the week
            -State - the actual state variable used in Q-learning (encodes the rank tuple)
        -Data Management
            - QB, RB, WR - sets of 8 players for each position that are used to define our state StateSpace
            -

=#

    function IntegratedFnc(YearFileLocation)
        #This function will define all of the inputs for Q-Learning (state, action, reward, and next state). In order to define the reward and next state, we need to conduct a rollout.
        #Inputs
            # Year_FileLocation: Path of location of folder with csv files for a yearly season
            # Players: Dictionary with players for that season and their integer tag. Generated by function PlayerTags, see subfunctions below. 
        #Outputs 
            #CumulativeReward: Array of Reward for every week so that we can plot it 
            #Q : Matrix of Action Value for each state, action pair 

        ####### INITIALIZE STUFF #################
        #Initialize State and Q-Table to empty. NOTE: This will need to change once I figure out how to handle Q from season to season
        State = []
        StateSpace = 1000
        ActionSpace = 7
        Q = zeros(StateSpace, ActionSpace)
        CumulativeReward = []

        #Initialize the Players that will be used for the season
        QB_Players, RB_Players, WR_Players = PlayerTags(YearFileLocation)

        #Initialize output textfile

        #Number of weeks in a specified season, used to determine number of iterations 
        NumWeeks = size(readdir(YearFileLocation),1)

        ####### BEGIN MEGA FOR LOOP ##################
        #Run through every weekly game in a season at a time
        for i in 1:NumWeeks 

            ####### STATE ##################
            #Define State (use Daniel's stateJustRank functions)
            #Either a random lineup or from previous week (if using from previous week, state will be defined after Q-table is updated)
            if isempty(State)
                #generate random lineup using week 1 data
                CurrentStateLineup = makeRandomLineup(QB_Players, RB_Players, WR_Players)
                currentWeekData = Rollout(YearFileLocation, 1, QB_Players, RB_Players, WR_Players)
                Rank = getPlayerRankings(CurrentStateLineup, currentWeekData)
                State = makeState(Rank)
            end 
                
            ####### ACTION ##################
            #NEEDS WORK: Define Action (need to implement exploration strategy) 
            Action = rand(1:7)

            ######## TRANSITION STATE #################
            #Transition State: accounts for the change in the roster based on the action but is based on current rankings. 
            #If we are on the first iteration (i.e. no rollouts have happened, just use the first week's data) Otherwise, use the data of the previous iteration)
            if i == 1
                preRolloutInt = 1
            else
                preRolloutInt = i - 1
            end
            TransitionRank = Transition(Rank,Action)
            prevWeekData = Rollout(YearFileLocation, preRolloutInt, QB_Players, RB_Players, WR_Players)
            #Keep track of which Player Integers correspond to the rankings in State
            NextStateLineup = RankingToPlayers(TransitionRank,prevWeekData)

            ######## ROLLOUT ################
            #Rollout Function Input/Output 
            #Input: Year, Week, Arrays of Players (see PlayerTags function)
            #Output: Table with Player Name, Player ID, Position, and Fantasy Points 
            #Daniel's function "getPlayerRankings" does this already but need to make sure that the input to that function is a dataset with only the 24 players we are dealing with or else 
            RolloutTable = Rollout(YearFileLocation, i, QB_Players, RB_Players, WR_Players)

            ######### NEXT STATE ################
            #Recalculate the state based on new rankings, Daniel's functions already do this:   
            NextStateRanking = getPlayerRankings(NextStateLineup, RolloutTable)
            NextState = makeState(NextStateRanking)

            ########## REWARD ##############
            #CumulativeReward will be an array with the reward for every week's lineup. We'll keep track of this to show our agent improving over time. 
            Reward = CalculateReward(NextStateLineup, NextStateRanking, Action, RolloutTable)
            push!(CumulativeReward, Reward)

            ########## Q-LEARNING ###############
            #Update Q Table
            QLearning(Q,State,Action,Reward,NextState)

            #Write out data to textfile

            #Update State and Rank for next iteration
            State = NextState
            Rank = NextStateRanking
 
        end
        return Q, CumulativeReward
    end

    function PlayerTags(YearFileLocation)
        #This function randomly selects 8 players from each position and assigns integer "tags" to each of them
        #Input: Path of location of folder with csv files for a yearly season 
        #Output: QB_Players, RB_Players, WR_Players, dictionaries that maps players to integers for each position. 

        #Step 1: Load in CSV of Week 1 for the input season as a dataframe
        Week1Path = YearFileLocation * "/week1.csv"
        Week1Data = CSV.read(Week1Path, DataFrame)
        
        #Using Walter's code from rankandrollout to create arrays for each position
        QBlist = []
        RBlist = []
        WRlist = []

        # Walter's code: get list of player names for each position to use for sorting
        for i = 1:size(Week1Data,1)
            if Week1Data.Pos[i] == "QB"
                push!(QBlist,Week1Data.Player[i])
            elseif Week1Data.Pos[i]== "RB"
                push!(RBlist,Week1Data.Player[i])
            elseif Week1Data.Pos[i] == "WR"
                push!(WRlist,Week1Data.Player[i])
            end
        end

        # Walter's code: pick random subset of 10 players at each position
        shuffleQBlist = randcycle(length(QBlist))
        shuffleRBlist = randcycle(length(RBlist))
        shuffleWRlist = randcycle(length(WRlist))

        QBsubset = QBlist[shuffleQBlist[1:8]]
        RBsubset = RBlist[shuffleRBlist[1:8]]
        WRsubset = WRlist[shuffleWRlist[1:8]]

        #Create Dictionaries for each position with an integer key and player name value
        QB_Players = Dict(i => QBsubset[i] for i=1:size(QBsubset,1))
        RB_Players = Dict(i => RBsubset[i] for i=1:size(RBsubset,1))
        WR_Players = Dict(i => WRsubset[i] for i=1:size(WRsubset,1))

        QB_Players, RB_Players, WR_Players
    end


    function RankingstoPlayers(LineupRank, weeklydata)
        #the reverse function of Daniel's "getPlayerRankings", this function will map the rankings in our state back to player names)
        #Input: Rankings of your lineup, weeklydata in the form generated by the RolloutFunction
        #Output: A dictionary with postion mapped to player name 

        # Separate the data by position
        QBdata = weeklydata[weeklydata.position .== "QB", :]
        RBdata = weeklydata[weeklydata.position .== "RB", :]
        WRdata = weeklydata[weeklydata.position .== "WR", :]

        # Sort the data by points from highest to lowest, so the first player has the highest score
        sort!(QBdata, [:points], rev=true) 
        sort!(RBdata, [:points], rev=true) 
        sort!(WRdata, [:points], rev=true) 

        QBName = weeklydata.player[LineupRank["QB"]]
        RBName = weeklydata.player[LineupRank["RB"]]
        WRName = weeklydata.player[LineupRank["WR"]]

        Lineup = Dict("QB" => QBName, "RB" => RBName, "WR" => WRName)
        
    end 

    function Rollout(YearFileLocation, weekNum, QB_Players, RB_Players, WR_Players)
        FilePath = YearFileLocation * "/week" * string(weekNum) * ".csv"

        #Step 1: Load all data into dataframe
        rawData = CSV.read(FilePath, DataFrame)

        #Step 2: We only need Player, Position, and Points columns
        limitedData = DataFrame(player = rawData.Player, position = rawData.Pos, points = rawData.StandardFantasyPoints)

        #Step 3: We only care about the subset of players in QB_Players, RB_Players and WR_Players 
        #merge player dictionaries into 1 dictionary with all players and tags
        Players = [QB_Players,RB_Players,WR_Players]

        #initialize data DataFrame
        RolloutTable = DataFrame(player = Any[], ID = Any[], position = Any[], points = Any[])

        #this is so inefficient but creating final dataframe with just the subset of players we are using and adding the player tag
        for j in 1:length(Players)
            for i in 1:length(Players[j])
                row = findfirst(limitedData.player .== Players[j][i])
                dataArray = [limitedData.player[row], i, limitedData.position[row], limitedData.points[row]]
                push!(RolloutTable, dataArray)
            end
        end
        RolloutTable
    end

    function Transition(Rank, Action)
        #implements actions to update the state tuple before we run the rollout, outputs ranks 

        transitionRank = Rank

        if Action == 1 # swap QB up
                new = transitionRank["QB"] - 1
                delete!(transitionRank, "QB")
                transitionRank["QB"] = new 

        elseif Action == 2 # swap QB down
                new = transitionRank["QB"] + 1
                delete!(transitionRank, "QB")
                transitionRank["QB"] = new 

        elseif Action == 3 # swap RB up
                new = transitionRank["RB"] - 1
                delete!(transitionRank, "RB")
                transitionRank["RB"] = new 

        elseif Action == 4 # swap RB down
                new = transitionRank["RB"] + 1
                delete!(transitionRank, "RB")
                transitionRank["RB"] = new

        elseif Action == 5 # swap WR up
                new = transitionRank["WR"] - 1
                delete!(transitionRank, "WR")
                transitionRank["WR"] = new

        elseif Action == 6 # swap WR down
                new = transitionRank["WR"] + 1
                delete!(transitionRank, "WR")
                transitionRank["WR"] = new

        end

        transitionRank
        
    end

    function CalculateReward(NextStateLineup, NextStateRanking, Action, RolloutTable)
        #The reward for each iteration will be composed of a transaction cost for trading a player plus the fantasy points scored by the lineup

        #Hyperparameters: We can vary how much the transaction cost of trading a specific position should be scaled by
        #General_Scalar is so that transaction cost is same order of magnitude as fantasy points
        #Total Transaction Cost = (Position_Transaction)* (General_Scalar) * (Inverse of New Rank)
        #Currently, trading down gives you a positive reward, not sure if we want to change this
        QB_Transaction = 1.5
        RB_Transaction = 1.5
        WR_Transaction = 1
        General_Scalar = 5

        if Action == 1 # swap QB up
            Transaction_Cost = -1 * Int(NextStateRanking["QB"])
            Scaled_Cost = General_Scalar * QB_Transaction * Transaction_Cost  

        elseif Action == 2 # swap QB down
            Transaction_Cost = Int(NextStateRanking["QB"])
            Scaled_Cost = General_Scalar * QB_Transaction * Transaction_Cost 

        elseif Action == 3 # swap RB up
                Transaction_Cost = -1* Int(NextStateRanking["RB"])
                Scaled_Cost = General_Scalar * RB_Transaction * Transaction_Cost 

        elseif Action == 4 # swap RB down
                Transaction_Cost = Int(NextStateRanking["RB"])
                Scaled_Cost = General_Scalar * RB_Transaction * Transaction_Cost 

        elseif Action == 5 # swap WR up
                Transaction_Cost = -1* Int(NextStateRanking["WR"])
                Scaled_Cost = General_Scalar * WR_Transaction * Transaction_Cost 

        elseif Action == 6 # swap WR down
                Transaction_Cost = Int(NextStateRanking["WR"])
                Scaled_Cost = General_Scalar * WR_Transaction * Transaction_Cost 

        elseif Action == 7 #do nothing
                Transaction_Cost = 0

        end

        #Fantasy Points for each player
        QBrow = findfirst(RolloutTable.player .== NextStateLineup["QB"])
        RBrow = findfirst(RolloutTable.player .== NextStateLineup["RB"])
        WRrow = findfirst(RolloutTable.player .== NextStateLineup["WR"])

        TotalFantasyPoints = RolloutTable.points[QBrow] + RolloutTable.points[RBrow] + RolloutTable.points[WRrow]

        TotalReward = Transaction_Cost + TotalFantasyPoints

    end

    function QLearning(Q,state,action,reward,next_state)
        gamma = 0.95
        alpha = 0.5
        
        Q[state,action] += alpha*(reward + gamma*maximum(Q[next_state,:]) - Q[state,action])
    end



