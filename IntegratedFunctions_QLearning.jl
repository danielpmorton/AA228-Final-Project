
```
OVERVIEW:

There will be a Main function that will loop through every week of a season and define the inputs for Q-learning as well as update the Q-table.

    Current Subfunctions that Zahra needs to fill out:
    -PlayerTags
    -RankingstoPlayers
    -TransitionState
    -CalculateReward 
    -QLearning 

    Current Issues that still need to be addressed:
    -How are we accounting for running multiple seasons or multiple initial lineups that all populate the same Q-table?
    -

````
    function Main(YearFileLocation, Players)
        #This function will define all of the inputs for Q-Learning (state, action, reward, and next state). In order to define the reward and next state, we need to conduct a rollout.
        #Inputs
            # Year_FileLocation: String of location of folder with csv files for a yearly season
            # Players: Dictionary with players for that season and their integer tag. Generated by function PlayerTags, see subfunctions below. 
        #Outputs 
            #CumulativeReward: Array of Reward for every week so that we can plot it 
            #Q : Matrix of Action Value for each state, action pair 


        #Initialize State and Q-Table to empty. NOTE: This will need to change once I figure out how to handle Q from season to season
        State = []
        StateSpace = 1000
        ActionSpace = 7
        Q = zeros(StateSpace, ActionSpace)

        #Number of weeks in a specified season, used to determine number of iterations 
        NumWeeks = size(readdir(YearFileLocation),1)

        #run through every weekly game in a season at a time
        for i in 1:NumWeeks 

            #STATE________________________________________________________________________________________
            #Define State (use Daniel's stateJustRank functions)
            #Either a random lineup or from previous week (if using from previous week, state will be defined after Q-table is updated)
            if isempty(state)
                #generate random lineup, Daniel's functions already have this option
                #NOTE: Daniel's function makeRandomLineup currently takes in a different input than I have here
                State = makeRandomLineup(Players)
                #Keep track of which Player Integers correspond to the rankings in State
                StatePlayerTags = RankingToPlayers(State) 
            end 
                
            
            #ACTION_________________________________________________________________________________________
            #NEEDS WORK: Define Action (need to implement exploration strategy) 
            if i < 5
                Action = rand(1:7)
            else
                #greedy action
                Action = argmax(Q)
            end


            #TRANSITION STATE_______________________________________________________________________________
            #Transition State: accounts for the change in the roster based on the action but is based on current rankings. 
            Transition_State = TransitionState(state,action)
            #Keep track of which Player Integers correspond to the rankings in State
            NextStatePlayerTags = RankingToPlayers(Transition_State)

            #ROLLOUT________________________________________________________________________________________
            #Rollout Function Input/Output 
                #Input: Year, Week, Array of Player Integer Tag (see PlayerTags function)
                #Output: Table with Player Integer, Rank for the week, Position, and Fantasy Points 

            #NEXT STATE_______________________________________________________________________________________
                #Recalculate the state based on new rankings, Daniel's functions already do this:
                    #getPlayerRankings (input: NextStatePlayerTags)
                    NextState = makeState  

            #REWARD____________________________________________________________________________________________
                #CumulativeReward will be an array with the reward for every week's lineup. We'll keep track of this to show our agent improving over time. 

            #Q-LEARNING___________________________________________________________________________________________
            #Update Q Table
            QLearning(Q,State,Action,Reward,NextState)

            #Update State for next iteration
            State = NextState
 
        end
        return Q, CumulativeReward
    end

    function PlayerTags(weeklydata)
        #This function assigns integer "tags" to each of the 24 players (8 of ea position) used in a season.
        #Input: weeklydata csv file
        #Output: Players, a dictionary that maps players to integers 

        #This function looks at the players for each position and chooses a random 8 players for each position (Walter's simulaterandomrollout function in rankandrollout does a lot of this)

        return Players 
    end

    function RankingstoPlayers(State, weeklydata)
        #the reverse function of Daniel's "getPlayerRankings", this function will map the rankings in our state back to the player tags generated by PlayerTags)
        return PlayerState
    end 

    function TransitionState(State, Action)
        #implements actions to update the state tuple before we run the rollout
        return TransitionState 
    end

    function CalculateReward(NextState, Action)
        
    end

    function QLearning(Q,state,action,reward,next_state)
        gamma = 0.95
        alpha = 0.5
        
        Q[state,action] += alpha*(reward + gamma*maximum(Q[next_state,:]) - Q[state,action])
    end